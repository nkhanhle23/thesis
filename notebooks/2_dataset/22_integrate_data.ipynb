{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration of FLS datasets (input) and real metric values (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook integrates the FLS datasets presented in the previous notebook (``21_apply_classifier_to_create_datasets.ipynb``) to the real metric values fetched from EDGAR database. \n",
    "\n",
    "For this project, we want to predict company performance based on each specific metrics, thus the metrics are separated into different datasets and the new data files are named after the metrics' official names on EDGAR, e.g. the metric Earnings Per Share will be saved under ``EarningsPerShareDiluted.csv``. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to integrate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will perform the following steps:\n",
    "1. Load the text data and filter for FLS.\n",
    "2. Rename columns and drop unnecessary ones for consistency with the metric data.\n",
    "3. Replace metric names to match those in the metric files.\n",
    "4. For each metric, merge the text data with the corresponding metric data based on CIK, year, and metric.\n",
    "5. Save the merged data into separate files named after each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_data(text_dataset, metrics_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Integrates the text dataset with the metric data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text_dataset : str\n",
    "        Path to the text dataset.\n",
    "    metrics_folder : str\n",
    "        Path to the folder containing the metric data.\n",
    "    output_folder : str\n",
    "        Path to the folder where the integrated data will be saved.\n",
    "    \"\"\"\n",
    "    # Read in the text data\n",
    "    df = pd.read_csv(text_dataset)\n",
    "    fls = df[df['Label'] == 'FLS']\n",
    "    \n",
    "    # Suppress warnings\n",
    "    pd.options.mode.chained_assignment = None  # Suppress SettingWithCopyWarning\n",
    "    \n",
    "    # Rename columns for consistency with the metric data\n",
    "    fls.rename(columns={'Metric': 'metric',\"CIK\":\"cik\",\"Year\":\"year\",'Sentence':'text','Item':'item'}, inplace=True)\n",
    "    fls.drop(columns=['index','Label','Company'], inplace=True)\n",
    "    fls['metric'] = fls['metric'].replace({\"Net Income\":\"Net Income (Loss)\",\n",
    "                                        \"EPS\":'Diluted Earnings per share',\n",
    "                                        \"Cash Flow (Investing)\":\"Net Cash from Investing Activities\",\n",
    "                                        \"Cash Flow (Financing)\":\"Net Cash from Financing Activities\",\n",
    "                                        \"Cash Flow (Operating)\":\"Net Cash from Operating Activities\",})\n",
    "    \n",
    "    # Create a list to store names of all the files\n",
    "    metric_files = [file for file in os.listdir(metrics_folder) if file.endswith('.csv')]\n",
    "    \n",
    "    # Loop through each metric file for integration\n",
    "    for metric_file in metric_files:\n",
    "        # Read in the metric file\n",
    "        metric = pd.read_csv(metrics_folder + metric_file)\n",
    "        \n",
    "        # Merge datasets based on CIK number, year and metric\n",
    "        merged_data = fls.merge(metric, on=['cik', 'year','metric'], how='inner')\n",
    "        merged_data = merged_data[['text','item', 'cik', 'year', 'val']]\n",
    "        \n",
    "        # Save data\n",
    "        if merged_data.empty:\n",
    "            print('No data for: ' + metric_file)\n",
    "        else:\n",
    "            merged_data.to_csv(output_folder + metric_file, index=False)\n",
    "            print('Saved: ' + metric_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the function to integrate and save data to the desired folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for: CostOfGoodsAndServicesSold.csv\n",
      "Saved: EarningsPerShareDiluted.csv\n",
      "Saved: EBIT.csv\n",
      "No data for: NetCashProvidedByUsedInContinuingOperations.csv\n",
      "Saved: NetCashProvidedByUsedInFinancingActivities.csv\n",
      "Saved: NetCashProvidedByUsedInInvestingActivities.csv\n",
      "Saved: NetIncomeLoss.csv\n",
      "Saved: RevenueFromContractWithCustomerExcludingAssessedTax.csv\n",
      "No data for: SellingGeneralAndAdministrativeExpense.csv\n",
      "No data for: CostOfGoodsAndServicesSold.csv\n",
      "Saved: EarningsPerShareDiluted.csv\n",
      "Saved: EBIT.csv\n",
      "No data for: NetCashProvidedByUsedInContinuingOperations.csv\n",
      "Saved: NetCashProvidedByUsedInFinancingActivities.csv\n",
      "Saved: NetCashProvidedByUsedInInvestingActivities.csv\n",
      "Saved: NetIncomeLoss.csv\n",
      "Saved: RevenueFromContractWithCustomerExcludingAssessedTax.csv\n",
      "No data for: SellingGeneralAndAdministrativeExpense.csv\n"
     ]
    }
   ],
   "source": [
    "integrate_data('../../data/01_interim/distilbert_dataset.csv', '../../data/00_raw/metric_data/', '../../data/02_processed/distilbert_data/')\n",
    "integrate_data('../../data/01_interim/finbert_dataset.csv', '../../data/00_raw/metric_data/', '../../data/02_processed/finbert_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After integrating the data, we now have 6 datasets representing 6 metrics for each FLS dataset. In total, there are 12 datasets. \n",
    "\n",
    "The last step that needs to be implemented for these datasets is to clean the data to the desired form that we can use directly for the performance prediction task. This is presented in the next notebook ``23_clean_data``. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
