{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Natural Language Processing (NLP)\n",
    "import spacy\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NetCashProvidedByUsedInInvestingActivities_train__text_clean.csv',\n",
       " 'EBIT_train__text_clean.csv',\n",
       " 'NetCashProvidedByUsedInFinancingActivities_train__text_clean.csv',\n",
       " 'RevenueFromContractWithCustomerExcludingAssessedTax_train__text_clean.csv',\n",
       " 'NetIncomeLoss_train__text_clean.csv',\n",
       " 'EarningsPerShareDiluted_train__text_clean.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all csv files from distilbert_data folder\n",
    "path = '../../data/02_processed/distilbert_data/train/'\n",
    "all_files = [file for file in os.listdir(path) if file.endswith('text_clean.csv')]\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EarningsPerShareDiluted_train__text_clean.csv',\n",
       " 'EBIT_train__text_clean.csv',\n",
       " 'NetCashProvidedByUsedInFinancingActivities_train__text_clean.csv',\n",
       " 'NetCashProvidedByUsedInInvestingActivities_train__text_clean.csv',\n",
       " 'NetIncomeLoss_train__text_clean.csv',\n",
       " 'RevenueFromContractWithCustomerExcludingAssessedTax_train__text_clean.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all csv files from distilbert_data folder\n",
    "fb_path = '../../data/02_processed/finbert_data/train/'\n",
    "fb_files = [file for file in os.listdir(fb_path) if file.endswith('text_clean.csv')]\n",
    "fb_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spacy en model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    '''\n",
    "    Lemmatize text using spacy's en_core_web_sm model\n",
    "    '''\n",
    "    sent = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NetCashProvidedByUsedInInvestingActivities_train__text_clean.csv...\n",
      "Processing EBIT_train__text_clean.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NetCashProvidedByUsedInFinancingActivities_train__text_clean.csv...\n",
      "Processing RevenueFromContractWithCustomerExcludingAssessedTax_train__text_clean.csv...\n",
      "Processing NetIncomeLoss_train__text_clean.csv...\n",
      "Processing EarningsPerShareDiluted_train__text_clean.csv...\n"
     ]
    }
   ],
   "source": [
    "for file in all_files:\n",
    "    print(f'Processing {file}...')\n",
    "    # Read csv file\n",
    "    df = pd.read_csv(path + file)\n",
    "    # Lemmatize text\n",
    "    df['text'] = df['text'].apply(lemmatize_text)\n",
    "    # Save lemmatized text to csv file\n",
    "    df.to_csv(path + file[:-15] + '_lemma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing EarningsPerShareDiluted_train__text_clean.csv...\n",
      "Processing EBIT_train__text_clean.csv...\n",
      "Processing NetCashProvidedByUsedInFinancingActivities_train__text_clean.csv...\n",
      "Processing NetCashProvidedByUsedInInvestingActivities_train__text_clean.csv...\n",
      "Processing NetIncomeLoss_train__text_clean.csv...\n",
      "Processing RevenueFromContractWithCustomerExcludingAssessedTax_train__text_clean.csv...\n"
     ]
    }
   ],
   "source": [
    "for file in fb_files:\n",
    "    print(f'Processing {file}...')\n",
    "    # Read csv file\n",
    "    df = pd.read_csv(fb_path + file)\n",
    "    # Lemmatize text\n",
    "    df['text'] = df['text'].apply(lemmatize_text)\n",
    "    # Save lemmatized text to csv file\n",
    "    df.to_csv(fb_path + file[:-15] + '_lemma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RSE scoring function\n",
    "def rse_scorer(y_true, y_pred):\n",
    "    true_mean = np.mean(y_true)\n",
    "    squared_error_num = np.sum(np.square(y_true - y_pred))\n",
    "    squared_error_den = np.sum(np.square(y_true - true_mean))\n",
    "    rse_loss = squared_error_num / squared_error_den\n",
    "    return -rse_loss  # Note the negative sign since GridSearchCV maximizes the score\n",
    "\n",
    "# Function to train a random forest regressor on the preprocessed data\n",
    "def train_random_forest_regressor(df, target_column, random_state=42):\n",
    "\n",
    "    # Define the pipeline\n",
    "    pipeline_tfidf = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_df=0.95, min_df=round(len(df) * 0.05))),\n",
    "        ('rf', RandomForestRegressor(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'rf__n_estimators': [100, 200, 500],\n",
    "        'rf__max_features': [1.0, 'sqrt', 'log2'],\n",
    "        'rf__max_depth': [None, 4, 8],\n",
    "        'rf__min_samples_split': [2, 10, 20],\n",
    "        'rf__min_samples_leaf': [1, 5, 10]\n",
    "    }\n",
    "    \n",
    "    # Add timer to record time\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"One or more of the test scores are non-finite\")\n",
    "\n",
    "        # Perform grid search for TF-IDF\n",
    "        with tqdm(total=len(param_grid['rf__n_estimators']) * len(param_grid['rf__max_features']) *\n",
    "                len(param_grid['rf__max_depth']) * len(param_grid['rf__min_samples_split']) *\n",
    "                len(param_grid['rf__min_samples_leaf']), desc='Grid Search Progress - TF-IDF') as pbar:\n",
    "\n",
    "            start_time_tfidf = time.time()  # Record the start time\n",
    "\n",
    "            grid_search_tfidf = GridSearchCV(pipeline_tfidf, param_grid, cv=10, scoring=make_scorer(rse_scorer), n_jobs=-1)\n",
    "            grid_search_tfidf.fit(df['text'], df[target_column])\n",
    "\n",
    "            end_time_tfidf = time.time()  # Record the end time\n",
    "            elapsed_time_tfidf = end_time_tfidf - start_time_tfidf  # Calculate the elapsed time\n",
    "\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "\n",
    "        # Access the best parameters and performance metrics for TF-IDF\n",
    "        print(f\"Best parameters for TF-IDF: {grid_search_tfidf.best_params_}\")\n",
    "        print(f\"Best negative RSE score for TF-IDF: {grid_search_tfidf.best_score_}\")\n",
    "        print(f\"Time taken for TF-IDF grid search: {elapsed_time_tfidf} seconds\")\n",
    "        \n",
    "\n",
    "    return grid_search_tfidf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EBIT_train__lemma.csv',\n",
       " 'NetIncomeLoss_train__lemma.csv',\n",
       " 'RevenueFromContractWithCustomerExcludingAssessedTax_train__lemma.csv',\n",
       " 'NetCashProvidedByUsedInFinancingActivities_train__lemma.csv',\n",
       " 'NetCashProvidedByUsedInInvestingActivities_train__lemma.csv',\n",
       " 'EarningsPerShareDiluted_train__lemma.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all csv files from distilbert_data folder\n",
    "path = '../../data/02_processed/distilbert_data/train/'\n",
    "all_files = [file for file in os.listdir(path) if file.endswith('lemma.csv')]\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EBIT'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0].split('.')[0].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EBIT_train__lemma.csv',\n",
       " 'NetIncomeLoss_train__lemma.csv',\n",
       " 'RevenueFromContractWithCustomerExcludingAssessedTax_train__lemma.csv',\n",
       " 'NetCashProvidedByUsedInFinancingActivities_train__lemma.csv',\n",
       " 'NetCashProvidedByUsedInInvestingActivities_train__lemma.csv',\n",
       " 'EarningsPerShareDiluted_train__lemma.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all csv files from distilbert_data folder\n",
    "fb_path = '../../data/02_processed/finbert_data/train/'\n",
    "fb_files = [file for file in os.listdir(fb_path) if file.endswith('lemma.csv')]\n",
    "fb_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------START TRAINING MODEL FOR EBIT--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [00:54<3:39:01, 54.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Best negative RSE score for TF-IDF: -0.7542797278023227\n",
      "Time taken for TF-IDF grid search: 54.30033564567566 seconds\n",
      "--------------DONE TRAINING MODEL FOR EBIT--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR NetIncomeLoss--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [27:41<111:43:23, 1662.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 500}\n",
      "Best negative RSE score for TF-IDF: -0.6191640708848944\n",
      "Time taken for TF-IDF grid search: 1661.9945952892303 seconds\n",
      "--------------DONE TRAINING MODEL FOR NetIncomeLoss--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR RevenueFromContractWithCustomerExcludingAssessedTax--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [16:09<65:08:41, 969.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 200}\n",
      "Best negative RSE score for TF-IDF: -0.46042747612464\n",
      "Time taken for TF-IDF grid search: 969.0958104133606 seconds\n",
      "--------------DONE TRAINING MODEL FOR RevenueFromContractWithCustomerExcludingAssessedTax--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR NetCashProvidedByUsedInFinancingActivities--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 0/243 [00:00<?, ?it/s]/home/nguyenk/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:990: RuntimeWarning: invalid value encountered in subtract\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n",
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [00:34<2:18:19, 34.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 1.0, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Best negative RSE score for TF-IDF: -inf\n",
      "Time taken for TF-IDF grid search: 34.29299759864807 seconds\n",
      "--------------DONE TRAINING MODEL FOR NetCashProvidedByUsedInFinancingActivities--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR NetCashProvidedByUsedInInvestingActivities--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [00:35<2:24:56, 35.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': 4, 'rf__max_features': 1.0, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 10, 'rf__n_estimators': 100}\n",
      "Best negative RSE score for TF-IDF: -1.7349015629101796\n",
      "Time taken for TF-IDF grid search: 35.93071484565735 seconds\n",
      "--------------DONE TRAINING MODEL FOR NetCashProvidedByUsedInInvestingActivities--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR EarningsPerShareDiluted--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [01:13<4:55:16, 73.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 500}\n",
      "Best negative RSE score for TF-IDF: -0.8755811797830078\n",
      "Time taken for TF-IDF grid search: 73.20788645744324 seconds\n",
      "--------------DONE TRAINING MODEL FOR EarningsPerShareDiluted--------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through all csv files\n",
    "for file in all_files:\n",
    "    \n",
    "    metric_name = file.split('.')[0].split('_')[0]\n",
    "    \n",
    "    print(f\"--------------START TRAINING MODEL FOR {metric_name}--------------\")\n",
    "    # Read csv file\n",
    "    df = pd.read_csv(path + file)\n",
    "    \n",
    "    # Train models\n",
    "    grid_search_tfidf = train_random_forest_regressor(df, 'target')\n",
    "    \n",
    "    # Save models\n",
    "    # If folder not available, create folder\n",
    "    if not os.path.exists('../../models/random_forest/':\n",
    "        os.makedirs('../../models/random_forest/')\n",
    "    # Save models to folder\n",
    "    with open('../../models/random_forest/' + metric_name + '_TF-IDF.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search_tfidf, f)\n",
    "    \n",
    "    #print(f\"MODELS FOR {metric_name} SAVED TO ../models/random_forest/{metric_name}\")\n",
    "    print(f\"--------------DONE TRAINING MODEL FOR {metric_name}--------------\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------START TRAINING MODEL FOR EBIT--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 0/243 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [01:27<5:54:34, 87.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Best negative RSE score for TF-IDF: -0.6669048019961213\n",
      "Time taken for TF-IDF grid search: 87.90625762939453 seconds\n",
      "--------------DONE TRAINING MODEL FOR EBIT--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR NetIncomeLoss--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [30:13<121:52:28, 1813.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 10, 'rf__n_estimators': 500}\n",
      "Best negative RSE score for TF-IDF: -0.6342420321432882\n",
      "Time taken for TF-IDF grid search: 1813.0084145069122 seconds\n",
      "--------------DONE TRAINING MODEL FOR NetIncomeLoss--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR RevenueFromContractWithCustomerExcludingAssessedTax--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [16:42<67:23:30, 1002.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 500}\n",
      "Best negative RSE score for TF-IDF: -0.4540991742725146\n",
      "Time taken for TF-IDF grid search: 1002.5164189338684 seconds\n",
      "--------------DONE TRAINING MODEL FOR RevenueFromContractWithCustomerExcludingAssessedTax--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR NetCashProvidedByUsedInFinancingActivities--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 0/243 [00:00<?, ?it/s]/home/nguyenk/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:990: RuntimeWarning: invalid value encountered in subtract\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n",
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [00:35<2:22:42, 35.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 1.0, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "Best negative RSE score for TF-IDF: -inf\n",
      "Time taken for TF-IDF grid search: 35.37861776351929 seconds\n",
      "--------------DONE TRAINING MODEL FOR NetCashProvidedByUsedInFinancingActivities--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR NetCashProvidedByUsedInInvestingActivities--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [00:37<2:31:41, 37.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 200}\n",
      "Best negative RSE score for TF-IDF: -2.7234771667435083\n",
      "Time taken for TF-IDF grid search: 37.60647773742676 seconds\n",
      "--------------DONE TRAINING MODEL FOR NetCashProvidedByUsedInInvestingActivities--------------\n",
      "\n",
      "\n",
      "--------------START TRAINING MODEL FOR EarningsPerShareDiluted--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [01:08<4:36:27, 68.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 10, 'rf__n_estimators': 200}\n",
      "Best negative RSE score for TF-IDF: -0.8471041113563806\n",
      "Time taken for TF-IDF grid search: 68.53978109359741 seconds\n",
      "--------------DONE TRAINING MODEL FOR EarningsPerShareDiluted--------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through all csv files\n",
    "for file in fb_files:\n",
    "    \n",
    "    metric_name = file.split('.')[0].split('_')[0]\n",
    "    \n",
    "    print(f\"--------------START TRAINING MODEL FOR {metric_name}--------------\")\n",
    "    # Read csv file\n",
    "    df = pd.read_csv(fb_path + file)\n",
    "    \n",
    "    # Train models\n",
    "    grid_search_tfidf = train_random_forest_regressor(df, 'target')\n",
    "    \n",
    "    # Save models\n",
    "    # If folder not available, create folder\n",
    "    if not os.path.exists('../../models/random_forest/finbert_data/' + metric_name):\n",
    "        os.makedirs('../../models/random_forest/finbert_data/' + metric_name)\n",
    "    # Save models to folder\n",
    "    with open('../../models/random_forest/finbert_data/' + metric_name + \"/\" + metric_name + '_TF-IDF.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search_tfidf, f)\n",
    "    \n",
    "    #print(f\"MODELS FOR {metric_name} SAVED TO ../models/random_forest/{metric_name}\")\n",
    "    print(f\"--------------DONE TRAINING MODEL FOR {metric_name}--------------\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
