{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text has to be preprocessed to be tokenized by TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import re \n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short\n",
    "import pickle\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../datasets/distilbert_data/EarningsPerShareDiluted.csv')\n",
    "df.dropna(inplace=True)\n",
    "text = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "text = text.apply(lambda x: strip_punctuation(x))\n",
    "\n",
    "# Remove multiple whitespaces\n",
    "text = text.apply(lambda x: strip_multiple_whitespaces(x))\n",
    "\n",
    "# Transform to lowercase\n",
    "text = text.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove stopwords\n",
    "text = text.apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Remove short words\n",
    "text = text.apply(lambda x: strip_short(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accordingly announced year end financial results fiscal 2015 provided guidance certain assumptions including ranges expected net sales earnings share quarter ending september 2015 fiscal year ending june 2016\n"
     ]
    }
   ],
   "source": [
    "# Initialize spacy en model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Lemmatize text\n",
    "text_lemma = text.apply(lambda x: ' '.join([token.lemma_ for token in nlp(x)]))\n",
    "\n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(text_lemma, open('../datasets/distilbert_data/preprocessed/EarningsPerShareDiluted_preprocessed.pkl', 'wb'))\n",
    "pickle.dump(text, open('../datasets/distilbert_data/preprocessed/EarningsPerShareDiluted_clean.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters\n",
    "min_count = round(len(corpus) * 0.05)\n",
    "vector_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.431023</td>\n",
       "      <td>0.175089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362868</td>\n",
       "      <td>0.164157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331876</td>\n",
       "      <td>0.173560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344063</td>\n",
       "      <td>0.192256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378586</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5    6    7    8    \\\n",
       "0  0.431023  0.175089  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
       "1  0.000000  0.362868  0.164157  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
       "2  0.000000  0.000000  0.331876  0.173560  0.000000  0.000000  0.0  0.0  0.0   \n",
       "3  0.000000  0.000000  0.000000  0.344063  0.192256  0.000000  0.0  0.0  0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.378586  0.194556  0.0  0.0  0.0   \n",
       "\n",
       "   9    ...  181  182  183  184  185  186  187  188  189       190  \n",
       "0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.287696  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.298121  \n",
       "2  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.301355  \n",
       "3  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.298701  \n",
       "4  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.294097  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize tfidf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=min_count)\n",
    "\n",
    "# Apply tfidf vectorizer\n",
    "tfidf = tfidf_vectorizer.fit_transform(text_lemma).toarray()\n",
    "\n",
    "# Final corpus\n",
    "corpus_tfidf = pd.DataFrame(tfidf)\n",
    "corpus_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into tokens\n",
    "corpus = [doc.split() for doc in text_lemma]\n",
    "\n",
    "# Create a gensim dictionary\n",
    "dictionary = Dictionary(corpus)\n",
    "\n",
    "# Remove rare and common tokens\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.95)\n",
    "\n",
    "# Train the model \n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n",
    "d2v = Doc2Vec(documents, vector_size=vector_size, min_count=min_count)\n",
    "\n",
    "# Final corpus\n",
    "corpus_d2v = pd.DataFrame([d2v.infer_vector(doc) for doc in corpus])\n",
    "corpus_d2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.059387</td>\n",
       "      <td>-0.010554</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>-0.012303</td>\n",
       "      <td>-0.075058</td>\n",
       "      <td>-0.031920</td>\n",
       "      <td>0.047558</td>\n",
       "      <td>-0.042538</td>\n",
       "      <td>-0.006812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>-0.016669</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>0.082972</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>0.060169</td>\n",
       "      <td>-0.032024</td>\n",
       "      <td>-0.021489</td>\n",
       "      <td>-0.020179</td>\n",
       "      <td>-0.030082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.056262</td>\n",
       "      <td>-0.009078</td>\n",
       "      <td>0.071133</td>\n",
       "      <td>0.022103</td>\n",
       "      <td>-0.013970</td>\n",
       "      <td>-0.061308</td>\n",
       "      <td>-0.030903</td>\n",
       "      <td>0.033770</td>\n",
       "      <td>-0.035434</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001515</td>\n",
       "      <td>-0.033771</td>\n",
       "      <td>0.106283</td>\n",
       "      <td>0.084190</td>\n",
       "      <td>0.062245</td>\n",
       "      <td>0.048808</td>\n",
       "      <td>-0.049486</td>\n",
       "      <td>-0.019710</td>\n",
       "      <td>-0.026810</td>\n",
       "      <td>-0.020993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.052209</td>\n",
       "      <td>-0.013164</td>\n",
       "      <td>0.062283</td>\n",
       "      <td>0.020480</td>\n",
       "      <td>-0.006454</td>\n",
       "      <td>-0.058924</td>\n",
       "      <td>-0.022883</td>\n",
       "      <td>0.037314</td>\n",
       "      <td>-0.033192</td>\n",
       "      <td>-0.007238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>-0.019106</td>\n",
       "      <td>0.087657</td>\n",
       "      <td>0.080449</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.047413</td>\n",
       "      <td>-0.032824</td>\n",
       "      <td>-0.025910</td>\n",
       "      <td>-0.016128</td>\n",
       "      <td>-0.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.050562</td>\n",
       "      <td>-0.008628</td>\n",
       "      <td>0.070373</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>-0.011930</td>\n",
       "      <td>-0.058947</td>\n",
       "      <td>-0.037681</td>\n",
       "      <td>0.033945</td>\n",
       "      <td>-0.034250</td>\n",
       "      <td>-0.006683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005099</td>\n",
       "      <td>-0.032245</td>\n",
       "      <td>0.102464</td>\n",
       "      <td>0.095816</td>\n",
       "      <td>0.063762</td>\n",
       "      <td>0.043741</td>\n",
       "      <td>-0.055836</td>\n",
       "      <td>-0.017600</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>-0.014997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.058458</td>\n",
       "      <td>-0.013427</td>\n",
       "      <td>0.082487</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>-0.017484</td>\n",
       "      <td>-0.060931</td>\n",
       "      <td>-0.040692</td>\n",
       "      <td>0.024879</td>\n",
       "      <td>-0.032765</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011062</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>0.112990</td>\n",
       "      <td>0.103496</td>\n",
       "      <td>0.060037</td>\n",
       "      <td>0.045561</td>\n",
       "      <td>-0.069985</td>\n",
       "      <td>-0.017748</td>\n",
       "      <td>-0.030944</td>\n",
       "      <td>-0.013211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.059387 -0.010554  0.074970  0.029473 -0.012303 -0.075058 -0.031920   \n",
       "1 -0.056262 -0.009078  0.071133  0.022103 -0.013970 -0.061308 -0.030903   \n",
       "2 -0.052209 -0.013164  0.062283  0.020480 -0.006454 -0.058924 -0.022883   \n",
       "3 -0.050562 -0.008628  0.070373  0.014288 -0.011930 -0.058947 -0.037681   \n",
       "4 -0.058458 -0.013427  0.082487  0.014441 -0.017484 -0.060931 -0.040692   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.047558 -0.042538 -0.006812  ...  0.015518 -0.016669  0.110024  0.082972   \n",
       "1  0.033770 -0.035434 -0.004560  ... -0.001515 -0.033771  0.106283  0.084190   \n",
       "2  0.037314 -0.033192 -0.007238  ...  0.008954 -0.019106  0.087657  0.080449   \n",
       "3  0.033945 -0.034250 -0.006683  ... -0.005099 -0.032245  0.102464  0.095816   \n",
       "4  0.024879 -0.032765 -0.014018  ... -0.011062 -0.038034  0.112990  0.103496   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.079165  0.060169 -0.032024 -0.021489 -0.020179 -0.030082  \n",
       "1  0.062245  0.048808 -0.049486 -0.019710 -0.026810 -0.020993  \n",
       "2  0.061396  0.047413 -0.032824 -0.025910 -0.016128 -0.015642  \n",
       "3  0.063762  0.043741 -0.055836 -0.017600 -0.025613 -0.014997  \n",
       "4  0.060037  0.045561 -0.069985 -0.017748 -0.030944 -0.013211  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n",
    "d2v = Doc2Vec(documents, vector_size=vector_size, min_count=min_count)\n",
    "\n",
    "# Final corpus\n",
    "corpus_d2v = pd.DataFrame([d2v.infer_vector(doc) for doc in corpus])\n",
    "corpus_d2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corpus_d2v, open('../datasets/distilbert_data/preprocessed/EarningsPerShareDiluted_D2V.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target to each of the models\n",
    "corpus_tfidf['target'] = df['test']\n",
    "corpus_d2v['target'] = df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.431023</td>\n",
       "      <td>0.175089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287696</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362868</td>\n",
       "      <td>0.164157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298121</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331876</td>\n",
       "      <td>0.173560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301355</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344063</td>\n",
       "      <td>0.192256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378586</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294097</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5    6    7    8  \\\n",
       "0  0.431023  0.175089  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
       "1  0.000000  0.362868  0.164157  0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
       "2  0.000000  0.000000  0.331876  0.173560  0.000000  0.000000  0.0  0.0  0.0   \n",
       "3  0.000000  0.000000  0.000000  0.344063  0.192256  0.000000  0.0  0.0  0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.378586  0.194556  0.0  0.0  0.0   \n",
       "\n",
       "     9  ...  182  183  184  185  186  187  188  189       190  target  \n",
       "0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.287696    2.82  \n",
       "1  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.298121    2.96  \n",
       "2  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.301355    3.35  \n",
       "3  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.298701    2.95  \n",
       "4  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.294097    4.82  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiy parameters\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test data\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(corpus_tfidf.drop(['target'], axis=1), corpus_tfidf['target'], test_size=0.2, random_state=random_state)\n",
    "X_train_d2v, X_test_d2v, y_train_d2v, y_test_d2v = train_test_split(corpus_d2v.drop(['target'], axis=1), corpus_d2v['target'], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.620784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>1.027042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model       RSE\n",
       "0    TFIDF  0.620784\n",
       "1  Doc2Vec  1.027042"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on TF-IDF features\n",
    "rf_tfidf = RandomForestRegressor(random_state=random_state)\n",
    "rf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Train the model on Doc2Vec features\n",
    "rf_d2v = RandomForestRegressor(random_state=random_state)\n",
    "rf_d2v.fit(X_train_d2v, y_train_d2v)\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred_tfidf = rf_tfidf.predict(X_test_tfidf)\n",
    "y_pred_d2v = rf_d2v.predict(X_test_d2v)\n",
    "\n",
    "# Evaluate the models\n",
    "# Function to calculate the relative squared error\n",
    "# Pros of RSE:\n",
    "# - It is scale independent --> can be used to compare models with different scales\n",
    "# - It is symmetric\n",
    "# - It is easy to interpret --> below 1 means that the model is better than the baseline, above 1 means that the model is worse than the baseline\n",
    "def rse(y_true, y_pred):\n",
    "    true_mean = np.mean(y_true)\n",
    "    squared_error_num = np.sum(np.square(y_true - y_pred))\n",
    "    squared_error_den = np.sum(np.square(y_true - true_mean))\n",
    "    rse_loss = squared_error_num / squared_error_den\n",
    "    return rse_loss  \n",
    "# Create a dataframe with the results\n",
    "results = pd.DataFrame({'model': ['TFIDF', 'Doc2Vec'], \n",
    "                        'RSE': [rse(y_test_tfidf, y_pred_tfidf), rse(y_test_d2v, y_pred_d2v)]\n",
    "                        })\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the results\n",
    "# The model with the lowest RSE is the best model\n",
    "# In this case, the Doc2Vec model is the best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not good, hyperparameters tuning required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "# Reset warnings to default behavior\n",
    "warnings.resetwarnings()\n",
    "random_forest_tuning_tfidf = RandomForestRegressor(random_state = random_state)\n",
    "param_grid = {\n",
    "   'n_estimators': [100, 200, 500],\n",
    "   'max_features': ['auto','sqrt', 'log2'],\n",
    "   'max_depth' : [4,5,6,7,8],\n",
    "   'min_samples_split': [2, 5, 10, 15, 20],\n",
    "   'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "# Suppress FitFailedWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"One or more of the test scores are non-finite\")\n",
    "#+7+\n",
    "    \n",
    "    # Your GridSearchCV code\n",
    "    GSCV_tfidf = GridSearchCV(estimator=random_forest_tuning, param_grid=param_grid, cv=5)\n",
    "    GSCV_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "    \n",
    "GSCV_tfidf.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset warnings to default behavior\n",
    "warnings.resetwarnings()\n",
    "random_forest_tuning_d2v = RandomForestRegressor(random_state = random_state)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "   'max_features': ['auto','sqrt', 'log2'],\n",
    "   'max_depth' : [4,5,6,7,8],\n",
    "   'min_samples_split': [2, 5, 10, 15, 20],\n",
    "   'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "# Suppress FitFailedWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"One or more of the test scores are non-finite\")\n",
    "\n",
    "    \n",
    "    # Your GridSearchCV code\n",
    "    GSCV_d2v = GridSearchCV(estimator=random_forest_tuning, param_grid=param_grid, cv=5)\n",
    "    GSCV_d2v.fit(X_train_d2v, y_train_d2v)\n",
    "    \n",
    "GSCV_d2v.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>15.373259</td>\n",
       "      <td>2.091342</td>\n",
       "      <td>0.860600</td>\n",
       "      <td>3.920875</td>\n",
       "      <td>0.147239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>4.313006</td>\n",
       "      <td>1.305175</td>\n",
       "      <td>0.537088</td>\n",
       "      <td>2.076778</td>\n",
       "      <td>0.760756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        MSE       MAE       RAE      RMSE  r2_score\n",
       "0    TFIDF  15.373259  2.091342  0.860600  3.920875  0.147239\n",
       "1  Doc2Vec   4.313006  1.305175  0.537088  2.076778  0.760756"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on TF-IDF features\n",
    "rf_tfidf = RandomForestRegressor(random_state=random_state, \n",
    "                                 max_depth=8, max_features='log2', \n",
    "                                 min_samples_leaf=2, min_samples_split=5,\n",
    "                                 n_estimators=100)\n",
    "rf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Train the model on Doc2Vec features\n",
    "rf_d2v = RandomForestRegressor(random_state=random_state, \n",
    "                               max_depth=8, max_features='log2', \n",
    "                               min_samples_leaf=1, min_samples_split=2,\n",
    "                               n_estimators=100)\n",
    "rf_d2v.fit(X_train_d2v, y_train_d2v)\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred_test_tfidf = rf_tfidf.predict(X_test_tfidf)\n",
    "y_pred_test_d2v = rf_d2v.predict(X_test_d2v)\n",
    "\n",
    "# Evaluate the models\n",
    "# Create a dataframe with the results\n",
    "results = pd.DataFrame({'model': ['TFIDF', 'Doc2Vec'], \n",
    "                        'RAE': [mean_absolute_error(y_test_tfidf, y_pred_test_tfidf) / (sum(abs(y_test_tfidf - y_test_tfidf.mean())) / len(y_test_tfidf)), mean_absolute_error(y_test_d2v, y_pred_test_d2v) / (sum(abs(y_test_d2v - y_test_d2v.mean())) / len(y_test_d2v))], # relative absolute error\n",
    "                        })\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accordingly announce year end financial result...</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accordingly announce year end financial result...</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accordingly announce year end financial result...</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accordingly announce year end financial result...</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accordingly announce year end financial result...</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  accordingly announce year end financial result...    2.82\n",
       "1  accordingly announce year end financial result...    2.96\n",
       "2  accordingly announce year end financial result...    3.35\n",
       "3  accordingly announce year end financial result...    2.95\n",
       "4  accordingly announce year end financial result...    4.82"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "df['text'] = text_lemma\n",
    "df = df[['text', 'val']]\n",
    "df.columns = ['text', 'target'] # Rename columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 0/243 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress - TF-IDF:   0%|          | 1/243 [21:05<85:06:09, 1265.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'rf__max_depth': None, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 10, 'rf__n_estimators': 100}\n",
      "Best negative RSE score for TF-IDF: -0.805833257125878\n",
      "Time taken for TF-IDF grid search: 1265.9904572963715 seconds\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vector Size Progress - Doc2Vec: 100%|██████████| 3/3 [1:38:55<00:00, 1978.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Doc2Vec (vector_size=50): {'rf__max_depth': 8, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 500}\n",
      "Best negative RSE score for Doc2Vec: -0.8896547563734345 (vector_size=50)\n",
      "Time taken for Doc2Vec grid search: 5935.244999170303 seconds\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RSE scoring function\n",
    "def rse_scorer(y_true, y_pred):\n",
    "    true_mean = np.mean(y_true)\n",
    "    squared_error_num = np.sum(np.square(y_true - y_pred))\n",
    "    squared_error_den = np.sum(np.square(y_true - true_mean))\n",
    "    rse_loss = squared_error_num / squared_error_den\n",
    "    return -rse_loss  # Note the negative sign since GridSearchCV maximizes the score\n",
    "\n",
    "# Custom transformer for Doc2Vec\n",
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=1, workers=None):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers if workers is not None else multiprocessing.cpu_count()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(X)]\n",
    "        self.model = Doc2Vec(vector_size=self.vector_size, window=self.window, min_count=self.min_count, workers=self.workers)\n",
    "        self.model.build_vocab(self.documents)\n",
    "        self.model.train(self.documents, total_examples=self.model.corpus_count, epochs=self.model.epochs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.infer_vector(doc.split()) for doc in X])\n",
    "    \n",
    "# Define the pipeline\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestRegressor(random_state=random_state))\n",
    "])\n",
    "\n",
    "pipeline_doc2vec = Pipeline([\n",
    "    ('doc2vec', Doc2VecTransformer()),\n",
    "    ('rf', RandomForestRegressor(random_state=random_state))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200, 500],\n",
    "    'rf__max_features': [1.0, 'sqrt', 'log2'],\n",
    "    'rf__max_depth': [None, 4, 8],\n",
    "    'rf__min_samples_split': [2, 10, 20],\n",
    "    'rf__min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Define the vector sizes to try for Doc2Vec\n",
    "doc2vec_vector_sizes = [50, 100, 200]\n",
    "\n",
    "# Add timer to record time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"One or more of the test scores are non-finite\")\n",
    "\n",
    "    # Perform grid search for TF-IDF\n",
    "    with tqdm(total=len(param_grid['rf__n_estimators']) * len(param_grid['rf__max_features']) *\n",
    "              len(param_grid['rf__max_depth']) * len(param_grid['rf__min_samples_split']) *\n",
    "              len(param_grid['rf__min_samples_leaf']), desc='Grid Search Progress - TF-IDF') as pbar:\n",
    "        \n",
    "        start_time_tfidf = time.time()  # Record the start time\n",
    "\n",
    "        grid_search_tfidf = GridSearchCV(pipeline_tfidf, param_grid, cv=5, scoring=make_scorer(rse_scorer), n_jobs=-1)\n",
    "        grid_search_tfidf.fit(train_df['text'], train_df['target'])\n",
    "        \n",
    "        end_time_tfidf = time.time()  # Record the end time\n",
    "        elapsed_time_tfidf = end_time_tfidf - start_time_tfidf  # Calculate the elapsed time\n",
    "\n",
    "        pbar.update(1)  # Update the progress bar\n",
    "        \n",
    "    # Access the best parameters and performance metrics for TF-IDF\n",
    "    print(f\"Best parameters for TF-IDF: {grid_search_tfidf.best_params_}\")\n",
    "    print(f\"Best negative RSE score for TF-IDF: {grid_search_tfidf.best_score_}\")\n",
    "    print(f\"Time taken for TF-IDF grid search: {elapsed_time_tfidf} seconds\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    \n",
    "    # Perform grid search for Doc2Vec with different vector sizes\n",
    "    best_doc2vec_vector_size = None\n",
    "    best_doc2vec_score = float('-inf')  # Initialize with negative infinity\n",
    "    \n",
    "    start_time_doc2vec = time.time()  # Record the start time\n",
    "    for vector_size in tqdm(doc2vec_vector_sizes, desc='Vector Size Progress - Doc2Vec'):\n",
    "        pipeline_doc2vec.set_params(doc2vec__vector_size=vector_size)\n",
    "        grid_search_doc2vec = GridSearchCV(pipeline_doc2vec, param_grid, cv=5, scoring=make_scorer(rse_scorer), n_jobs=-1)\n",
    "        grid_search_doc2vec.fit(train_df['text'], train_df['target'])\n",
    "        \n",
    "        # Check if the current vector size has a better score than the previous best\n",
    "        if grid_search_doc2vec.best_score_ > best_doc2vec_score:\n",
    "            best_doc2vec_score = grid_search_doc2vec.best_score_\n",
    "            best_doc2vec_vector_size = vector_size\n",
    "            best_doc2vec_params = grid_search_doc2vec.best_params_\n",
    "            best_doc2vec_model = grid_search_doc2vec\n",
    "            \n",
    "    \n",
    "    end_time_doc2vec = time.time()  # Record the end time\n",
    "    elapsed_time_doc2vec = end_time_doc2vec - start_time_doc2vec  # Calculate the elapsed time\n",
    "\n",
    "    print(f\"Best parameters for Doc2Vec (vector_size={best_doc2vec_vector_size}): {best_doc2vec_params}\")\n",
    "    print(f\"Best negative RSE score for Doc2Vec: {best_doc2vec_score} (vector_size={best_doc2vec_vector_size})\")\n",
    "    print(f\"Time taken for Doc2Vec grid search: {elapsed_time_doc2vec} seconds\")\n",
    "    print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train RSE</th>\n",
       "      <th>Test RSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.733966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>0.889655</td>\n",
       "      <td>0.865065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Train RSE  Test RSE\n",
       "0    TFIDF   0.805833  0.733966\n",
       "1  Doc2Vec   0.889655  0.865065"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the models on the test set\n",
    "y_pred_tfidf = grid_search_tfidf.predict(test_df['text'])\n",
    "y_pred_d2v = grid_search_doc2vec.predict(test_df['text'])\n",
    "# Function to calculate the relative squared error\n",
    "# Pros of RSE:\n",
    "# - It is scale independent --> can be used to compare models with different scales\n",
    "# - It is symmetric\n",
    "# - It is easy to interpret --> below 1 means that the model is better than the baseline, above 1 means that the model is worse than the baseline\n",
    "def rse(y_true, y_pred):\n",
    "    return -rse_scorer(y_true, y_pred)  # Reverse the sign of the RSE score to get the RSE\n",
    "\n",
    "# Train RSE\n",
    "train_tfidf_score = -1 * grid_search_tfidf.best_score_\n",
    "train_doc2vec_score = -1 * best_doc2vec_score\n",
    "# Test RSE\n",
    "test_tfidf_score = rse(test_df['target'], y_pred_tfidf)\n",
    "test_doc2vec_score = rse(test_df['target'], y_pred_d2v)\n",
    "\n",
    "# Create a dataframe with the results\n",
    "results = pd.DataFrame({'Model': ['TFIDF', 'Doc2Vec'], \n",
    "                        'Train RSE': [train_tfidf_score, train_doc2vec_score],\n",
    "                        'Test RSE': [test_tfidf_score, test_doc2vec_score]\n",
    "                        })\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF performs better than Doc2Vec in both train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both models\n",
    "with open('../datasets/distilbert_data/models/EarningsPerShareDiluted/EarningsPerShareDiluted_TFIDF.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search_tfidf, f)\n",
    "with open('../datasets/distilbert_data/models/EarningsPerShareDiluted/EarningsPerShareDiluted_D2V.pkl', 'wb') as f:\n",
    "    pickle.dump(best_doc2vec_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
